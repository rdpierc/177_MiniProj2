{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster as sk_cluster\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage      \n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv('cleaned_data.csv')\n",
    "clinton_trump_texts = pd.read_table('clinton_trump_user_classes.txt', names = ['UserID', 'Class'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinton_trump_texts_agg = cleaned_data.groupby('UserID')['Hash'].apply(\" \".join)\n",
    "clinton_trump_sklearn = pd.DataFrame({'User_id':clinton_trump_texts_agg.index,'All_hashtag':clinton_trump_texts_agg.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sk_text.TfidfVectorizer(stop_words='english',max_features=4, min_df=1, max_df=300)\n",
    "matrix = vectorizer.fit_transform(clinton_trump_sklearn.All_hashtag.values)\n",
    "tfidf = matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matrix.todense(),index = clinton_trump_texts_agg.index, columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df,clinton_trump_texts, on='UserID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s apply clustering and compare the clustering result against a known ground truth. In the file “clinton_trump_user_classes.txt”, we have the ground truth “class” membership for each user id in the data. Class 0 corresponds to Trump followers, while class 1 corresponds to Clinton followers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the k-means algorithm (K=2) and the two different variations of the agglomerative clustering algorithm (MAX-based and SSE-based)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the confusion matrix, precision, recall, and F-measure for (1) k-means, (2) MAX-based agglomerative clustering, and (3) SSE-based agglomerative clustering. Compare their performance and include your conclusions in your report. See sample code in lab 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kmeans = sk_cluster.KMeans(n_clusters=2, n_init=10, max_iter=300)\n",
    "kmeans_label = kmeans.fit_predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('\\nPrinting cluster assignment:')\n",
    "print(kmeans_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "error = kmeans.inertia_       #SSE; Sum of squared distances of samples to their closest cluster center.\n",
    "print (\"The total error of the clustering is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array(merged_df.Class.values)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(truth, kmeans.labels_, labels=[0, 1])   # first row: 0 ; second row: 1\n",
    "print(confusion)\n",
    "print(metrics.precision_score(truth, kmeans.labels_, average='weighted'))\n",
    "print(metrics.recall_score(truth, kmeans.labels_, average='weighted'))\n",
    "print(metrics.f1_score(truth, kmeans.labels_, average= 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAX based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ag1 = sk_cluster.AgglomerativeClustering(linkage = 'complete', n_clusters = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_labels = ag1.fit_predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('\\nPrinting cluseter assignment:')\n",
    "ag_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(truth, ag1.labels_, labels=[0, 1])   # first row: 0 ; second row: 1\n",
    "print(confusion)\n",
    "print(metrics.precision_score(truth, ag1.labels_, average='weighted'))\n",
    "print(metrics.recall_score(truth, ag1.labels_, average='weighted'))\n",
    "print(metrics.f1_score(truth, ag1.labels_, average= 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSE based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag2 = sk_cluster.AgglomerativeClustering(linkage = 'ward', n_clusters = 2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_labels2 = ag2.fit_predict(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('\\nPrinting cluseter assignment:')\n",
    "ag_labels2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(truth, ag2.labels_, labels=[0, 1])   # first row: 0 ; second row: 1\n",
    "print(confusion)\n",
    "print(metrics.precision_score(truth, ag2.labels_, average='weighted'))\n",
    "print(metrics.recall_score(truth, ag2.labels_, average='weighted'))\n",
    "print(metrics.f1_score(truth, ag2.labels_, average= 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For k-means, look at the two centers (centroids) and print the top-30 hashtags/handles with the highest tfidf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "print ('Cluster Centroids')\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_order_centroids = kmeans.cluster_centers_.argsort()    # argsort() returns the indices that would sort an array.\n",
    "des_order_centroids = asc_order_centroids[:,::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "print (\"All the terms:\")\n",
    "print(terms, '\\n')\n",
    "\n",
    "for i in range(2):\n",
    "    print (\"Cluster:\", i)\n",
    "    for ind in des_order_centroids[i, :30]:\n",
    "        print (terms[ind])\n",
    "    print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asc_order_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the two respective word clouds of the two centers (centroids) by using hashtags/handles and their tfidf values. Hint: Use function fit_words() that comes with wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clustering of Hashtags/handles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, you apply the k-means algorithm. Create a plot of the SSE error of the k-means algorithm as a function of the number of clusters, for k up to 20, in order to determine the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error = np.zeros(4)\n",
    "for k in range(1,4):\n",
    "    kmeans = sk_cluster.KMeans(n_clusters=k, n_init=10, max_iter=500)\n",
    "    kmeans.fit_predict(tfidf.transpose())\n",
    "    error[k] = kmeans.inertia_\n",
    "\n",
    "plt.plot(range(1, 4), error[1:])\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the k-means algorithm for the optimal number of clusters you identified in the last task. Print some hashtags/handles in each cluster. From the hashtags/handles in each cluster, try to deduce what is the topic it concerns. Include your conclusions in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = sk_cluster.KMeans(n_clusters=6, n_init=10, max_iter=300)\n",
    "kmeans_label = kmeans.fit_predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('\\nPrinting cluster assignment:')\n",
    "print(kmeans_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "error = kmeans.inertia_       #SSE; Sum of squared distances of samples to their closest cluster center.\n",
    "print (\"The total error of the clustering is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array(merged_df.Class.values)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(truth, kmeans.labels_, labels=[0, 1])   # first row: 0 ; second row: 1\n",
    "print(confusion)\n",
    "print(metrics.precision_score(truth, kmeans.labels_, average='weighted')) # weighted: the average precision of all clusters is returned\n",
    "print(metrics.recall_score(truth, ag2.labels_, average='weighted'))  # weighted: the average recall of all clusters is returned\n",
    "print(metrics.f1_score(truth, ag2.labels_, average= 'weighted'))     # weighted: the average f1 of all clusters is returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
